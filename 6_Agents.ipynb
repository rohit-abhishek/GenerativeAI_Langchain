{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e1d5b6",
   "metadata": {},
   "source": [
    "# Using Agent capability with Langchain\n",
    "\n",
    "To create agent in langchain we need 3 things \n",
    "1. Docstring - What is this tool supposed to do. this should include what when and how this tool should be used for LLM to understand\n",
    "2. Parameter Names - What these parameter names are e.g. send_parms(employee_id:int, employee_name:str) instead of send_params(params_1:int, params_2:str) \n",
    "3. If parameters names are not clear we should include the details of parameters in docstring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0502b879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a59e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea692e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set langsmit tracing off \n",
    "# os.environ['LANGSMITH_TRACING'] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c81af8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# create llms \n",
    "google_llm = ChatGoogleGenerativeAI(temperature=0, model=\"gemini-3-flash-preview\")\n",
    "openai_llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "ollama_llm = ChatOllama(temperature=0, model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145f51a3",
   "metadata": {},
   "source": [
    "### Creating tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93a5b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool \n",
    "\n",
    "@tool\n",
    "def add(x:float, y:float, z:float|None=None) -> float: \n",
    "    \"Add 'x' and 'y' \"\n",
    "    return x + y \n",
    "\n",
    "@tool\n",
    "def substract(x:float, y:float) -> float: \n",
    "    \"Substract 'y' from 'x' \"\n",
    "    return x - y \n",
    "\n",
    "@tool\n",
    "def multiply(x:float, y:float) -> float: \n",
    "    \"Multiply 'x' and 'y' \"\n",
    "    return x * y \n",
    "\n",
    "@tool\n",
    "def divide(x:float, y:float) -> float: \n",
    "    \"Divide 'x' by 'y' \"\n",
    "    return x / y \n",
    "\n",
    "@tool\n",
    "def exponential(x:float, y:float) -> float: \n",
    "    \"Raise 'x' to the power of 'y' \"\n",
    "    return x ** y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f1650f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description=\"Add 'x' and 'y'\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x10fa08e00>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455e18d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60b3e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Add 'x' and 'y' \",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'},\n",
       "  'z': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Z'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the arugument schema (pay attention to z which can be number of None and value is defaulted to None)\n",
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2631d8fd",
   "metadata": {},
   "source": [
    "Reverting the tool add to include only x and y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbe8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(x:float, y:float) -> float: \n",
    "    \"Add 'x' and 'y' \"\n",
    "    return x + y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4a0837",
   "metadata": {},
   "source": [
    "### Creating Agent\n",
    "```\n",
    "Agent in LCEL is constructed as - \n",
    "agent = (\n",
    "    <input parameters, including chat history and user query><br>\n",
    "    | <prompt> <br>\n",
    "    | <LLM with tools> <br>\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a753d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder \n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", (\n",
    "        \"You are a helpful assistant. When answering user's query you should first use one of the tool provided. \"\n",
    "        \"After using the tool, the tool output will be provided in scratchpad below.\"\n",
    "        \"If you have the answer in scratchpad, you should not use anymore tools and instead answer directly to user.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"), \n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcd35b",
   "metadata": {},
   "source": [
    "``` \n",
    "Agent scratchpad will have data in ToolMessage() format telling LLM that this is output from the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70801794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide reference of tools to LLM \n",
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "tools = [add, multiply, divide, substract, exponential]\n",
    "\n",
    "agent:RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x['input'], \n",
    "        \"chat_history\": lambda x : x['chat_history'], \n",
    "        \"agent_scratchpad\": lambda x : x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt \n",
    "    | openai_llm.bind_tools(tools, tool_choice=\"any\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985469f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 217, 'total_tokens': 234, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-Csp8njxAG8jK1KGcDDX1FOjt8vMEC', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b7446-71dd-7dd0-b641-b8238f501e56-0', tool_calls=[{'name': 'add', 'args': {'x': 5, 'y': 10}, 'id': 'call_S0ensG8peZEfuLaBiekLHlVU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 217, 'output_tokens': 17, 'total_tokens': 234, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this agent and AIMessage content will be empty as this is going to make a call to a tool\n",
    "tool_call = agent.invoke({\n",
    "    \"input\": \"What is 5 + 10\", \n",
    "    \"chat_history\": []\n",
    "})\n",
    "tool_call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea3e8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'x': 5, 'y': 10},\n",
       "  'id': 'call_S0ensG8peZEfuLaBiekLHlVU',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee285b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add': <function __main__.add(x: float, y: float) -> float>,\n",
       " 'multiply': <function __main__.multiply(x: float, y: float) -> float>,\n",
       " 'divide': <function __main__.divide(x: float, y: float) -> float>,\n",
       " 'substract': <function __main__.substract(x: float, y: float) -> float>,\n",
       " 'exponential': <function __main__.exponential(x: float, y: float) -> float>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now call the tool for that create a dictionary with name2tool \n",
    "name2tool = {tool.name : tool.func for tool in tools}\n",
    "name2tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ebaef85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now execute the tool\n",
    "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]] (\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "tool_exec_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c9fdb",
   "metadata": {},
   "source": [
    "``` \n",
    "Now we have the answer, shove this answer to agent scratchpad as Tool message for LLM to understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4518adf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 247, 'total_tokens': 264, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-CspQGdgGVHsXZcNc8DNjVRRoNwwt5', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b7456-f7cc-7ae2-9c39-a15a385849ac-0', tool_calls=[{'name': 'add', 'args': {'x': 5, 'y': 10}, 'id': 'call_yuNpKJkHUDZWQy1LkZyr6cuY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 247, 'output_tokens': 17, 'total_tokens': 264, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_exec_content}\",\n",
    "    tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 5 + 10\", \n",
    "    \"chat_history\": [], \n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7966d8",
   "metadata": {},
   "source": [
    "``` \n",
    "Since the tool_choice is set to any content field of AI message will be empty. To get the output you can have 2 ways - \n",
    "a. set tool_choice=\"auto\"; in this case final answer will appear in content field. \n",
    "b. set tool_choice=\"any/required\"; and have final_output tool created which will have final answer. (Preferred way!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62b0ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool \n",
    "def final_answer(answer:str, tools_used:list[str]) -> str:\n",
    "    \"\"\" Use this tool to provide the final answer to the user. \n",
    "    The answer should be in natural language as this will be provided to user directly.\n",
    "    tools_used should contain list of tools used within the `scratchpad`\n",
    "    \"\"\"\n",
    "\n",
    "    return {'answer': answer, \"tools_used\": tools_used}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38ca480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide reference of tools to LLM \n",
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "tools = [final_answer, add, multiply, divide, substract, exponential]\n",
    "\n",
    "agent:RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x['input'], \n",
    "        \"chat_history\": lambda x : x['chat_history'], \n",
    "        \"agent_scratchpad\": lambda x : x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt \n",
    "    | openai_llm.bind_tools(tools, tool_choice=\"any\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2050c99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 279, 'total_tokens': 296, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_c4585b5b9c', 'id': 'chatcmpl-CspcVz2yzK0Hx7WMyA1WfpiSrAlkR', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b7462-8d79-7850-9627-de857c0e1066-0', tool_calls=[{'name': 'add', 'args': {'x': 5, 'y': 10}, 'id': 'call_jsafMCjpnkWoHkjztDNRaMFL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 279, 'output_tokens': 17, 'total_tokens': 296, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this agent and AIMessage content will be empty as this is going to make a call to a tool\n",
    "tool_call = agent.invoke({\n",
    "    \"input\": \"What is 5 + 10\", \n",
    "    \"chat_history\": []\n",
    "})\n",
    "tool_call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab2466aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now execute the tool\n",
    "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]] (\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "tool_exec_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13e3a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_exec_content}\",\n",
    "    tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 5 + 10\", \n",
    "    \"chat_history\": [], \n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc08b3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 309, 'total_tokens': 336, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_c4585b5b9c', 'id': 'chatcmpl-CspdNNOYQsvJ6yfKDfephj6eNHdem', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b7463-60ca-7680-8481-a2ef25284762-0', tool_calls=[{'name': 'final_answer', 'args': {'answer': '5 + 10 equals 15.', 'tools_used': ['functions.add']}, 'id': 'call_77hOPBTbEs11gsndIklSoCxz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 309, 'output_tokens': 27, 'total_tokens': 336, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "427b8a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now execute the tool\n",
    "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]] (\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "tool_exec_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99a20e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'final_answer',\n",
       "  'args': {'answer': '5 + 10 equals 15.', 'tools_used': ['functions.add']},\n",
       "  'id': 'call_77hOPBTbEs11gsndIklSoCxz',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd4a0e2",
   "metadata": {},
   "source": [
    "``` \n",
    "Calling one after another manaully is not advisable. Instead create a class called CustomAgentExecutor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "315cc9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final_answer': <function __main__.final_answer(answer: str, tools_used: list[str]) -> str>,\n",
       " 'add': <function __main__.add(x: float, y: float) -> float>,\n",
       " 'multiply': <function __main__.multiply(x: float, y: float) -> float>,\n",
       " 'divide': <function __main__.divide(x: float, y: float) -> float>,\n",
       " 'substract': <function __main__.substract(x: float, y: float) -> float>,\n",
       " 'exponential': <function __main__.exponential(x: float, y: float) -> float>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now call the tool for that create a dictionary with name2tool \n",
    "name2tool = {tool.name : tool.func for tool in tools}\n",
    "name2tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d091889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "\n",
    "class CustomAgentExecutor:\n",
    "    chat_history: list[BaseMessage]\n",
    "\n",
    "    def __init__(self, max_iterations:int=3):\n",
    "        self.chat_history = [] \n",
    "        self.max_iterations = max_iterations\n",
    "        self.agent:RunnableSerializable = (\n",
    "            {\n",
    "                \"input\": lambda x: x[\"input\"], \n",
    "                \"chat_history\": lambda x: x[\"chat_history\"], \n",
    "                \"agent_scratchpad\": lambda x : x[\"agent_scratchpad\"]\n",
    "            }\n",
    "            | prompt \n",
    "            | openai_llm.bind_tools(tools, tool_choice=\"any\")\n",
    "        )\n",
    "\n",
    "    def invoke(self, input:str) -> dict:\n",
    "        \"\"\" runs agent iteratively until get final answer \"\"\"\n",
    "        count = 0 \n",
    "        agent_scratchpad = [] \n",
    "\n",
    "        # iterate till max_iterations \n",
    "        while count < self.max_iterations:\n",
    "            tool_call = self.agent.invoke({\n",
    "                \"input\": input, \n",
    "                \"chat_history\": self.chat_history, \n",
    "                \"agent_scratchpad\": agent_scratchpad\n",
    "            })\n",
    "\n",
    "            agent_scratchpad.append(tool_call)\n",
    "\n",
    "            # extract tool name (assumption is llm is calling one tool at a time)\n",
    "            tool_name = tool_call.tool_calls[0][\"name\"]\n",
    "            tool_args = tool_call.tool_calls[0][\"args\"]\n",
    "            tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
    "            tool_out = name2tool[tool_name](**tool_args)\n",
    "\n",
    "            # create tool message\n",
    "            tool_exec = ToolMessage(\n",
    "                content=f\"{tool_out}\", \n",
    "                tool_call_id=tool_call_id\n",
    "            )\n",
    "\n",
    "            # add tool message to scratchpad \n",
    "            agent_scratchpad.append(tool_exec)\n",
    "\n",
    "            print(f\"{count}: {tool_name}({tool_args})\")\n",
    "            count+=1 \n",
    "\n",
    "            if tool_name == \"final_answer\":\n",
    "                break \n",
    "        \n",
    "        answer = tool_out[\"answer\"]\n",
    "        self.chat_history.extend([\n",
    "            HumanMessage(content=input), \n",
    "            AIMessage(content=answer)\n",
    "        ])\n",
    "\n",
    "        return json.dumps(tool_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4fb108f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final_answer': <function __main__.final_answer(answer: str, tools_used: list[str]) -> str>,\n",
       " 'add': <function __main__.add(x: float, y: float) -> float>,\n",
       " 'multiply': <function __main__.multiply(x: float, y: float) -> float>,\n",
       " 'divide': <function __main__.divide(x: float, y: float) -> float>,\n",
       " 'substract': <function __main__.substract(x: float, y: float) -> float>,\n",
       " 'exponential': <function __main__.exponential(x: float, y: float) -> float>}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6378d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: add({'x': 6, 'y': 18})\n",
      "1: final_answer({'answer': '6 + 18 equals 24.', 'tools_used': ['functions.add']})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"answer\": \"6 + 18 equals 24.\", \"tools_used\": [\"functions.add\"]}'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = CustomAgentExecutor()\n",
    "agent_executor.invoke(input=\"What is 6 + 18?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b3f87f",
   "metadata": {},
   "source": [
    "# Not good for complicated tasks i.e. 6 + 18*5 as it assumes calls are going to be sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7333d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generativeai-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
